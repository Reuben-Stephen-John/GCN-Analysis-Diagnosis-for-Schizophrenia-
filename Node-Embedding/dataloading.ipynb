{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from karateclub import NetMF\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_fc_matrices=np.load('../source_data/fc/fc_matrices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_fc_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetMF embedding logic using karate club module\n",
    "def netmf_embedding(graph, dimensions=16, order=2):\n",
    "    model = NetMF(dimensions=dimensions, order=order,seed=21)\n",
    "    model.fit(graph)\n",
    "    return model.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object(sub_conn_matrix, label, dimensions, order, threshold=0.5):\n",
    "    adjacency_matrix = (sub_conn_matrix > threshold).astype(float)\n",
    "    graph = nx.from_numpy_matrix(adjacency_matrix)\n",
    "    netmf_embeddings = netmf_embedding(graph,dimensions, order)  # Replace this with your actual embedding logic\n",
    "    \n",
    "    # Extract node features from the embeddings\n",
    "    node_features = torch.tensor(netmf_embeddings, dtype=torch.float32)\n",
    "    edge_index = torch.tensor(adjacency_matrix.nonzero(), dtype=torch.long)\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, y=torch.tensor(label))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC (Healthy Controls): 25 subjects\n",
      "AVH- (Auditory Verbal Hallucinations Negative): 23 subjects\n",
      "AVH+ (Auditory Verbal Hallucinations Positive): 23 subjects\n"
     ]
    }
   ],
   "source": [
    "# Read the TSV data into a pandas DataFrame\n",
    "df = pd.read_csv('../Full-Dataset/participants.tsv', delimiter='\\t')\n",
    "\n",
    "# Count the occurrences of each group\n",
    "group_counts = df['group'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"HC (Healthy Controls):\", group_counts.get('HC', 0), \"subjects\")\n",
    "print(\"AVH- (Auditory Verbal Hallucinations Negative):\", group_counts.get('AVH-', 0), \"subjects\")\n",
    "print(\"AVH+ (Auditory Verbal Hallucinations Positive):\", group_counts.get('AVH+', 0), \"subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 25 subjects\n",
      "Label 1: 23 subjects\n",
      "Label 2: 23 subjects\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "label=[]\n",
    "for i in range(len(subject_fc_matrices)):\n",
    "    if i <25:\n",
    "        label.append(0)\n",
    "    if i >= 25 and i<48:\n",
    "        label.append(1)\n",
    "    if i >=48:\n",
    "        label.append(2)\n",
    "\n",
    "all_labels = np.array(label)\n",
    "# Find unique labels and their counts\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "# Create a dictionary to store the counts for each unique label\n",
    "label_counts = dict(zip(unique_labels, counts))\n",
    "# Print the results\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} subjects\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(subject_fc_matrices)):\n",
    "    sub_conn_matrix=subject_fc_matrices[i]\n",
    "    subject_data = create_data_object(sub_conn_matrix,label=all_labels[i], dimensions=32, order=2,threshold=0.5)\n",
    "    data_list.append(subject_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "dimensions=32\n",
    "order=2\n",
    "threshold=0.5\n",
    "# First, split into training and test sets\n",
    "subject_fc_train, subject_fc_test, labels_train, labels_test = train_test_split(\n",
    "    subject_fc_matrices, all_labels, test_size=test_size, random_state=42)\n",
    "# Then, split the training set into training and validation sets\n",
    "subject_fc_train, subject_fc_val, labels_train, labels_val = train_test_split(\n",
    "    subject_fc_train, labels_train, test_size=validation_size / (1 - test_size), random_state=42)\n",
    "\n",
    "# Example: Create PyTorch Geometric Data objects for each set\n",
    "data_train = [create_data_object(sub_conn_matrix,labels, dimensions, order,threshold) for sub_conn_matrix, labels in zip(subject_fc_train, labels_train)]\n",
    "data_val = [create_data_object(sub_conn_matrix,labels, dimensions, order,threshold) for sub_conn_matrix, labels in zip(subject_fc_val, labels_val)]\n",
    "data_test = [create_data_object(sub_conn_matrix,labels, dimensions, order,threshold) for sub_conn_matrix, labels in zip(subject_fc_test, labels_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use PyTorch DataLoader to handle batches if needed\n",
    "batch_size = 4  # Adjust according to your needs\n",
    "data_loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "data_loader_val = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
    "data_loader_test = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[156, 32], edge_index=[2, 1282], y=[4], batch=[156], ptr=[5])\n"
     ]
    }
   ],
   "source": [
    "batch_train = next(iter(data_loader_train))\n",
    "print(batch_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
