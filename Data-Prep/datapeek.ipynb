{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_file_path = \"..\\Full-Dataset\\sub-01\\\\anat\\sub-01_T1w.nii.gz\"\n",
    "nii_image = nib.load(nii_file_path)\n",
    "image_data= nii_image.get_fdata()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image(slice_number):\n",
    "    slice_array = image_data[:, :, slice_number]\n",
    "    plt.imshow(slice_array, cmap=\"gray\")\n",
    "    plt.title(\"Healthy Control Anat MRI (SUB-01)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add the figure label to the bottom of the image\n",
    "    plt.text(0.5, -0.15, \"Figure 1.b\", transform=plt.gca().transAxes,\n",
    "             fontsize=12, ha='center')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = image_data.shape\n",
    "num_channels = dimensions[-1] if len(dimensions) > 3 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_slider = widgets.IntSlider(\n",
    "    min=1,\n",
    "    max=dimensions[2] - 1,\n",
    "    step=1,\n",
    "    value=dimensions[2] - 1,\n",
    "    description=\"Slice\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a17078f8a34919bd859ecd72975e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=179, description='Slice', max=179, min=1), Output()), _dom_classes=('widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_image(slice_number)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(update_image, slice_number=slice_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'Full-Dataset\\sub-01\\func\\sub-01_task-speech_bold.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Reuben's Code's\\PyTorch\\Schizophrenia\\venv\\lib\\site-packages\\nibabel\\loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     stat_result \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(filename)\n\u001b[0;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Full-Dataset\\\\sub-01\\\\func\\\\sub-01_task-speech_bold.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Reuben's Code's\\PyTorch\\Schizophrenia\\Data-Prep\\datapeek.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nii_file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFull-Dataset\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msub-01\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mfunc\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msub-01_task-speech_bold.nii.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nii_image \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39;49mload(nii_file_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m image_data\u001b[39m=\u001b[39m nii_image\u001b[39m.\u001b[39mget_fdata()  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dimensions \u001b[39m=\u001b[39m image_data\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Reuben's Code's\\PyTorch\\Schizophrenia\\venv\\lib\\site-packages\\nibabel\\loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     stat_result \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstat(filename)\n\u001b[0;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such file or no access: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m stat_result\u001b[39m.\u001b[39mst_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m ImageFileError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmpty file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'Full-Dataset\\sub-01\\func\\sub-01_task-speech_bold.nii.gz'"
     ]
    }
   ],
   "source": [
    "nii_file_path = \"Full-Dataset\\sub-01\\\\func\\sub-01_task-speech_bold.nii.gz\"\n",
    "nii_image = nib.load(nii_file_path)\n",
    "image_data= nii_image.get_fdata()  \n",
    "dimensions = image_data.shape\n",
    "num_channels = dimensions[3] if len(dimensions) > 3 else 1\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Reuben's Code's\\PyTorch\\Schizophrenia\\Data-Prep\\datapeek.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m slice_array \u001b[39m=\u001b[39m image_data[:, :, \u001b[39m2\u001b[39;49m,\u001b[39m152\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(slice_array, cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Reuben%27s%20Code%27s/PyTorch/Schizophrenia/Data-Prep/datapeek.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mMRI Image\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "slice_array = image_data[:, :, 2,152]\n",
    "plt.imshow(slice_array, cmap=\"gray\")\n",
    "plt.title(\"MRI Image\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_slider = widgets.SelectionSlider(\n",
    "    options=list(range(dimensions[2])),\n",
    "    description=\"Slice\",\n",
    "    continous_update=True\n",
    ")\n",
    "channel_slider = widgets.SelectionSlider(\n",
    "    options=list(range(num_channels)),\n",
    "    description=\"Channel\",\n",
    "    continuous_update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_4D(channel_number,slice_number):\n",
    "    #channel_number=3\n",
    "    slice_array = image_data[:, :, slice_number,channel_number]\n",
    "    plt.imshow(slice_array, cmap=\"gray\")\n",
    "    plt.title(\"Healthy Control fMRI (SUB-12)\")\n",
    "    plt.colorbar()\n",
    "    plt.text(0.5, -0.15, \"Figure 1.a\", transform=plt.gca().transAxes,\n",
    "             fontsize=12, ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mri_view(file_path):\n",
    "    nii_file_path = file_path\n",
    "    nii_image = nib.load(nii_file_path)\n",
    "    image_data= nii_image.get_fdata()  \n",
    "    dimensions = image_data.shape\n",
    "    print(dimensions)\n",
    "    num_channels = dimensions[3] if len(dimensions) > 3 else 1\n",
    "    slice_slider = widgets.SelectionSlider(\n",
    "        options=list(range(dimensions[2])),\n",
    "        description=\"Slice\",\n",
    "        continous_update=True\n",
    "    )\n",
    "    channel_slider = widgets.SelectionSlider(\n",
    "        options=list(range(num_channels)),\n",
    "        description=\"Channel\",\n",
    "        continuous_update=True\n",
    "    )\n",
    "    def update_image_4D(channel_number,slice_number):\n",
    "        #channel_number=3\n",
    "        slice_array = image_data[:, :, slice_number,channel_number]\n",
    "        plt.imshow(slice_array, cmap=\"gray\")\n",
    "        plt.title(\"functional MRI Image\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    interact(update_image_4D,channel_number=channel_slider ,slice_number=slice_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 32, 341)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dda09ebb09747a59bd3018c91fc2057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Channel', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mri_view(\"C:\\Reuben's Code's\\PyTorch\\Schizophrenia\\Full-Dataset\\sub-12\\\\func\\sub-12_task-speech_bold.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 32, 341)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1451e46fab0d456b9e8654faa2b9a74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Channel', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mri_view(\"C:\\Reuben's Code's\\PyTorch\\Schizophrenia\\Full-Dataset\\sub-01\\\\func\\sub-01_task-speech_bold.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
